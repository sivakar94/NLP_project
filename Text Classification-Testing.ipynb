{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from random import shuffle\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import model_selection, preprocessing\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.classify import SklearnClassifier\n",
    "from nltk import FreqDist\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "import numpy\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from scipy import sparse\n",
    "import re\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer as SIA\n",
    "from sklearn import decomposition, ensemble\n",
    "import xgboost\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "import seaborn as sns\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "import spacy\n",
    "from spacy import displacy\n",
    "from collections import Counter\n",
    "from pprint import pprint\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_char=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read JSON scripts into dataframe\n",
    "df=pd.read_json('data/dialogues-combined.json')\n",
    "df.columns=['script_number','scene','character','dialogue','attributes','char_groups']\n",
    "df['scene']=df['scene'].str.split('|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select most frequent characters\n",
    "x=df.character.value_counts().head(top_char).keys()\n",
    "df=df.loc[df['character'].isin(x)]\n",
    "df=df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot count of dialogues\n",
    "fig = plt.figure(figsize=(8,6))\n",
    "df.groupby('character').dialogue.count().plot.bar(ylim=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Gender Heuristic to the data\n",
    "gender_df = pd.read_csv('data/gender.csv',na_filter=False)\n",
    "gender_dict=dict(zip(gender_df.name, gender_df.gender))\n",
    "df['gender']=df['character'].apply(lambda x: 'unknown' if gender_dict.get(x,'') =='' else  gender_dict[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label encoding\n",
    "encoder = preprocessing.LabelEncoder()\n",
    "char = encoder.fit_transform(df['character'])\n",
    "#df = df.drop('character', axis=1)\n",
    "df['category_id']=char\n",
    "labels = df.category_id\n",
    "\n",
    "#create an ordered mapping between character and category_id\n",
    "category_df = df[['character', 'category_id']].drop_duplicates().sort_values('category_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>script_number</th>\n",
       "      <th>scene</th>\n",
       "      <th>character</th>\n",
       "      <th>dialogue</th>\n",
       "      <th>attributes</th>\n",
       "      <th>char_groups</th>\n",
       "      <th>gender</th>\n",
       "      <th>category_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1350</td>\n",
       "      <td>[DESERTED CAR PARK, EXT, NIGHT]</td>\n",
       "      <td>SHIRLEY</td>\n",
       "      <td>Look at ya, not a mark on ya. And you think yo...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[KEVIN, SHIRLEY]</td>\n",
       "      <td>female</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1350</td>\n",
       "      <td>[R&amp;R, INT, NIGHT]</td>\n",
       "      <td>JACK</td>\n",
       "      <td>Oi. Where have you been? Huh? What were the te...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[JACK, RONNIE]</td>\n",
       "      <td>male</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1350</td>\n",
       "      <td>[R&amp;R, INT, NIGHT]</td>\n",
       "      <td>RONNIE</td>\n",
       "      <td>Nothing. Nothing. I'll be with you in two minu...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[JACK, RONNIE]</td>\n",
       "      <td>female</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1350</td>\n",
       "      <td>[R&amp;R, INT, NIGHT]</td>\n",
       "      <td>JACK</td>\n",
       "      <td>Well I've got mates here I wanted to have a ch...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[JACK, RONNIE]</td>\n",
       "      <td>male</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1350</td>\n",
       "      <td>[R&amp;R, INT, NIGHT]</td>\n",
       "      <td>RONNIE</td>\n",
       "      <td>Alright. Two minutes.</td>\n",
       "      <td>[]</td>\n",
       "      <td>[JACK, RONNIE]</td>\n",
       "      <td>female</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   script_number                            scene character  \\\n",
       "0           1350  [DESERTED CAR PARK, EXT, NIGHT]   SHIRLEY   \n",
       "1           1350                [R&R, INT, NIGHT]      JACK   \n",
       "2           1350                [R&R, INT, NIGHT]    RONNIE   \n",
       "3           1350                [R&R, INT, NIGHT]      JACK   \n",
       "4           1350                [R&R, INT, NIGHT]    RONNIE   \n",
       "\n",
       "                                            dialogue attributes  \\\n",
       "0  Look at ya, not a mark on ya. And you think yo...         []   \n",
       "1  Oi. Where have you been? Huh? What were the te...         []   \n",
       "2  Nothing. Nothing. I'll be with you in two minu...         []   \n",
       "3  Well I've got mates here I wanted to have a ch...         []   \n",
       "4                              Alright. Two minutes.         []   \n",
       "\n",
       "        char_groups  gender  category_id  \n",
       "0  [KEVIN, SHIRLEY]  female           16  \n",
       "1    [JACK, RONNIE]    male            7  \n",
       "2    [JACK, RONNIE]  female           13  \n",
       "3    [JACK, RONNIE]    male            7  \n",
       "4    [JACK, RONNIE]  female           13  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preview dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>attributes</th>\n",
       "      <th>category_id</th>\n",
       "      <th>char_groups</th>\n",
       "      <th>character</th>\n",
       "      <th>dialogue</th>\n",
       "      <th>gender</th>\n",
       "      <th>scene</th>\n",
       "      <th>script_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>I’m… I'm sick, I'm sick Max ... I need to get...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  attributes category_id char_groups character  \\\n",
       "0         []        None          []      None   \n",
       "\n",
       "                                            dialogue   gender scene  \\\n",
       "0   I’m… I'm sick, I'm sick Max ... I need to get...  unknown    []   \n",
       "\n",
       "  script_number  \n",
       "0          None  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scene=[]\n",
    "dialogue=\"\"\" I’m… I'm sick, I'm sick Max ... I need to get better, I need to... I need to recover and you won't let me... will ya? I loved you with all my heart ... and now ... even now ... there’s still something there. How disgusting is that? To still have feelings like that. But not you though eh? Not you. The only person you love is yourself ... is Max Branning ... king of the world ain't he? That's what you tell yourself. I know the truth, inside you‘re just, you're just a frightened, sad, lonely little boy, frightened kid who’s dad didn’t love him enough. And it’s all... it's all so pathetic. \"\"\"\n",
    "attributes=[]\n",
    "char_groups=[]\n",
    "gender='unknown'\n",
    "\n",
    "test_df=pd.DataFrame.from_dict([{'script_number': None,'scene': scene,'character': None,'dialogue':dialogue,'attributes':attributes,'char_groups':char_groups,'gender':gender,'category_id':None}])\n",
    "df=df.append(test_df)\n",
    "test_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text preprocessing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LemmaTokenizer(object):\n",
    "    def __init__(self):\n",
    "        self.wnl = WordNetLemmatizer()\n",
    "    def __call__(self, articles):\n",
    "        return [self.wnl.lemmatize(t) for t in word_tokenize(articles)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Non-Textual Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method to parse attributes into dictionary\n",
    "def parseAttribures(attr):\n",
    "    if attr is None:\n",
    "        return None\n",
    "    else:\n",
    "        return dict((x,attr.count(x)) for x in set(attr))\n",
    "\n",
    "\n",
    "#Scene Details as features\n",
    "def f_scene_func(df):\n",
    "    f_scene=DictVectorizer().fit_transform(df['scene'].apply(parseAttribures))\n",
    "    return f_scene\n",
    "\n",
    "# Script's parenthetical attributes as features\n",
    "def f_attributes_func(df):\n",
    "    f_attributes=DictVectorizer().fit_transform(df['attributes'].apply(parseAttribures)) \n",
    "    max_abs_scaler = preprocessing.MaxAbsScaler()\n",
    "    f_attributes_scaled = max_abs_scaler.fit_transform(f_attributes)   # parenthetical attributes as features  - SCALED\n",
    "    return f_attributes_scaled\n",
    "\n",
    "# Top 100 Character groups as features\n",
    "def f_char_groups_func(df):\n",
    "    top_char_groups=list(df['char_groups'].apply('|'.join).value_counts().head(100).keys())\n",
    "    f_char_groups=DictVectorizer().fit_transform(df['char_groups'].apply('|'.join).apply(lambda x: x  if x  in top_char_groups else 'UNKNOWN').apply(lambda x:[x]).apply(parseAttribures))\n",
    "    return f_char_groups\n",
    "\n",
    "# Gender as a Feature\n",
    "def f_gender_func(df):\n",
    "    f_gender=DictVectorizer().fit_transform(df['gender'].apply(lambda x:[x]).apply(parseAttribures))\n",
    "    return f_gender\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text Metadata features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractMeta(x):\n",
    "    return {'count_chars': len(x),\n",
    "            'count_whitespace': x.count(\" \"),\n",
    "            'count_dots': x.count(\".\")-3*(x.count(\"...\")),\n",
    "            'count_cdots': x.count(\"...\"),\n",
    "            'count_excl': x.count(\"!\"),\n",
    "            'count_ques': x.count(\"?\"),\n",
    "            'count_num': len(re.findall(\"\\d\", x)),\n",
    "            'count_upper': len(re.findall(\"[A-Z]\", x)),\n",
    "            'count_words': len(x) / (x.count(\" \") + 1),\n",
    "            'count_sent': x.count(\" \") / (x.count(\".\") + 1)           \n",
    "           }\n",
    "\n",
    "def f_meta_func(df):\n",
    "    f_meta=DictVectorizer().fit_transform(df['dialogue'].apply(extractMeta))\n",
    "    max_abs_scaler = preprocessing.MaxAbsScaler()\n",
    "    f_meta_scaled = max_abs_scaler.fit_transform(f_meta)  # Metadata features scaled\n",
    "    return f_meta_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### N-gram counts and frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Count Vectors\n",
    "def f_count_func(df):\n",
    "    count_vect = CountVectorizer(analyzer='word', stop_words='english',token_pattern=r'\\w{1,}')\n",
    "    f_count=count_vect.fit_transform(df['dialogue'])\n",
    "    return f_count\n",
    "\n",
    "\n",
    "#TF-IDF unigram\n",
    "def f_tfidf_func(df):\n",
    "    tfidf_vect = TfidfVectorizer(analyzer='word',token_pattern=r\"\\b\\w[\\w']+\\b\", tokenizer=LemmaTokenizer(),max_features=5000)\n",
    "    f_tfidf=tfidf_vect.fit_transform(df['dialogue'])\n",
    "    return f_tfidf\n",
    "\n",
    "#TF-IDF n-gram\n",
    "def f_tfidf_ngram_func(df):\n",
    "    tfidf_ngram_vect = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', ngram_range=(2,3), max_features=5000)\n",
    "    f_tfidf_ngram=tfidf_ngram_vect.fit_transform(df['dialogue'])\n",
    "    return f_tfidf_ngram\n",
    "\n",
    "#TF-IDF char n-gram\n",
    "def f_tfidf_ngram_chars_func(df):\n",
    "    tfidf_ngram_chars_vect = TfidfVectorizer(analyzer='char', token_pattern=r'\\w{1,}', ngram_range=(2,3), max_features=5000)\n",
    "    f_tfidf_ngram_chars=tfidf_ngram_chars_vect.fit_transform(df['dialogue'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### POS Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tag import CRFTagger\n",
    "import pycrfsuite\n",
    "\n",
    "\n",
    "def f_pos_tags_func(df):\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    TAGGER_PATH = \"data/crfpostagger\"   # pre-trained POS-tagger \n",
    "    tagger = CRFTagger()  \n",
    "    tagger.set_model_file(TAGGER_PATH)\n",
    "\n",
    "    pos_tags=tagger.tag_sents([word.lower() for word in s] for s in df['dialogue'].apply(tokenizer.tokenize))\n",
    "    pos_tags_str = []\n",
    "    for word in pos_tags:\n",
    "        pos_tags_con=[w[0]+'_'+w[1] for w in word]\n",
    "        pos_tags_str.append(' '.join(pos_tags_con))\n",
    "    tfidf_pos = TfidfVectorizer(lowercase=False,max_features=5000)\n",
    "    f_pos_tags=tfidf_pos.fit_transform(pos_tags_str)\n",
    "    return f_pos_tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### POS Tags a metadata features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### count of each POS type \n",
    "def check_pos_tag(x, flag):\n",
    "    cnt = 0\n",
    "    try:\n",
    "        for tup in x:\n",
    "            ppo = list(tup)[1]\n",
    "            if ppo in pos_family[flag]:\n",
    "                cnt += 1\n",
    "    except:\n",
    "        pass\n",
    "    return cnt\n",
    "\n",
    "\n",
    "def extractPOS(x):\n",
    "    count_noun=check_pos_tag(x,'noun')\n",
    "    count_verb=check_pos_tag(x,'verb')\n",
    "    count_adj=check_pos_tag(x,'adj')\n",
    "    count_adv=check_pos_tag(x,'adv')\n",
    "    count_pron=check_pos_tag(x,'pron')\n",
    "    count_sum=count_noun+count_verb+count_adj+count_adv+count_pron+1\n",
    "    return {'count_noun': count_noun/count_sum,\n",
    "            'count_verb': count_verb/count_sum,\n",
    "            'count_adj': count_adj/count_sum,\n",
    "            'count_adv': count_adv/count_sum,\n",
    "            'count_pron': count_pron/count_sum,\n",
    "           }\n",
    "\n",
    "\n",
    "def f_pos_count_func(df):\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    TAGGER_PATH = \"data/crfpostagger\"   # pre-trained POS-tagger \n",
    "    tagger = CRFTagger()  \n",
    "    tagger.set_model_file(TAGGER_PATH)\n",
    "    pos_family = {\n",
    "        'noun' : ['NN','NNS','NNP','NNPS'],\n",
    "        'pron' : ['PRP','PRP$','WP','WP$'],\n",
    "        'verb' : ['VB','VBD','VBG','VBN','VBP','VBZ'],\n",
    "        'adj' :  ['JJ','JJR','JJS'],\n",
    "        'adv' : ['RB','RBR','RBS','WRB']\n",
    "    }\n",
    "    f_pos_count=DictVectorizer().fit_transform(df['dialogue'].apply(tokenizer.tokenize).apply(lambda x: [word.lower() for word in x]).apply(tagger.tag).apply(extractPOS))\n",
    "    return f_pos_count\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Topic Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a LDA Model\n",
    "\n",
    "#tm_vect = TfidfVectorizer(analyzer='word',token_pattern=r\"\\b\\w[\\w']+\\b\",stop_words='english', max_features=5000)\n",
    "\n",
    "def f_topics_func(df):\n",
    "    tm_vect = CountVectorizer(analyzer='word', stop_words='english',token_pattern=r\"\\b\\w[\\w']+\\b\")\n",
    "    f_tm=tm_vect.fit_transform(df['dialogue'])\n",
    "    lda_model = decomposition.LatentDirichletAllocation(n_components=20, learning_method='online', max_iter=20)\n",
    "    f_topics = lda_model.fit_transform(f_tm)\n",
    "    return f_topics"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Preview the topic words\n",
    "topic_word = lda_model.components_ \n",
    "vocab = tm_vect.get_feature_names()\n",
    "\n",
    "# view the topic models\n",
    "n_top_words = 10\n",
    "topic_summaries = []\n",
    "for i, topic_dist in enumerate(topic_word):\n",
    "    topic_words = numpy.array(vocab)[numpy.argsort(topic_dist)][:-(n_top_words+1):-1]\n",
    "    topic_summaries.append('|'.join(topic_words))\n",
    "pprint(topic_summaries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Named Entity Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_ner_func(df):\n",
    "    spacy_nlp = spacy.load('en')\n",
    "    doc = df['dialogue'].apply(spacy_nlp).apply(lambda x : [X.label_ for X in x.ents])\n",
    "    def getCountNER(attr):\n",
    "        return dict((x,attr.count(x)) for x in set(attr))\n",
    "    f_ner=DictVectorizer().fit_transform(doc.apply(getCountNER))  # Number of each type of named entity -> as a feature\n",
    "    return f_ner\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sentiment"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_sent_func(df):\n",
    "    sia = SIA()\n",
    "    sentiment= df['dialogue'].apply(sia.polarity_scores)\n",
    "    f_sent=DictVectorizer().fit_transform(df['dialogue'].apply(sia.polarity_scores)) #Sentiment polarity score as feature\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    f_sent_scaled = min_max_scaler.fit_transform(f_sent.toarray()) # Sentiment features scaled\n",
    "    return f_sent_scaled\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define classifiers to be evaluated\n",
    "\n",
    "# Define feature selector\n",
    "feature_selector=SelectKBest(chi2, k=1000)\n",
    "\n",
    "#Create pipelines for each classifier type\n",
    "svm_pipeline = Pipeline([('chi2', feature_selector),('svm', LinearSVC())])\n",
    "nb_pipeline = Pipeline([('chi2', feature_selector),('nb', MultinomialNB())])\n",
    "lr_pipeline = Pipeline([('chi2', feature_selector),('lr', LogisticRegression())])\n",
    "\n",
    "# Create classifier list\n",
    "models = [\n",
    "    OneVsRestClassifier(svm_pipeline),\n",
    "    OneVsRestClassifier(nb_pipeline),\n",
    "    OneVsRestClassifier(lr_pipeline)\n",
    "]\n",
    "model_names=['SVM', 'Naive-Bayes','Max-Entropy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross validation function\n",
    "def cross_validation(features,labels, fold):\n",
    "    cv_df = pd.DataFrame(index=range(fold * len(models)))\n",
    "    entries = []\n",
    "    for model,model_name in zip(models,model_names):\n",
    "        accuracies = cross_val_score(model, features, labels, scoring='accuracy', cv=fold)\n",
    "        for fold_idx, accuracy in enumerate(accuracies):\n",
    "            entries.append((model_name, fold_idx, accuracy))\n",
    "    cv_df = pd.DataFrame(entries, columns=['model_name', 'fold_idx', 'accuracy'])\n",
    "    return cv_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Only Textual Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining Features\n",
    "features=sparse.hstack([f_tfidf_func(df),f_topics_func(df),f_pos_tags_func(df),f_ner_func(df),f_meta_func(df),f_pos_count_func(df),f_sent_func(df)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and test\n",
    "X_train=features.tocsr()[:-1]\n",
    "X_test=features.tocsr()[-1]\n",
    "y_train=labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>character</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>category_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>TANYA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            character\n",
       "category_id          \n",
       "19              TANYA"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training and Testing\n",
    "model=OneVsRestClassifier(svm_pipeline)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "category_df.set_index('category_id').iloc[y_pred]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Textual Features with Scene details and Parenthetical Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining Features\n",
    "features=sparse.hstack([features,f_scene_func(df),f_attributes_func(df)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and test\n",
    "X_train=features.tocsr()[:-1]\n",
    "X_test=features.tocsr()[-1]\n",
    "y_train=labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>character</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>category_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>STACEY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            character\n",
       "category_id          \n",
       "17             STACEY"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training and Testing\n",
    "model=OneVsRestClassifier(svm_pipeline)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "category_df.set_index('category_id').iloc[y_pred]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Textual Features with Scene details,  Parenthetical Attributes and character groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining Features\n",
    "features=sparse.hstack([features,f_char_groups_func(df)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and test\n",
    "X_train=features.tocsr()[:-1]\n",
    "X_test=features.tocsr()[-1]\n",
    "y_train=labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>character</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>category_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DAWN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            character\n",
       "category_id          \n",
       "3                DAWN"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training and Testing\n",
    "model=OneVsRestClassifier(svm_pipeline)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "category_df.set_index('category_id').iloc[y_pred]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Textual Features with Scene details,  Parenthetical Attributes and character groups and gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining Features\n",
    "features=sparse.hstack([features, f_gender_func(df)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and test\n",
    "X_train=features.tocsr()[:-1]\n",
    "X_test=features.tocsr()[-1]\n",
    "y_train=labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>character</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>category_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DAWN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            character\n",
       "category_id          \n",
       "3                DAWN"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training and Testing\n",
    "model=OneVsRestClassifier(svm_pipeline)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "category_df.set_index('category_id').iloc[y_pred]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
